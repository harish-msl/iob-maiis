# Voice Interface - Quick Start Guide

## üé§ Overview

The Voice Interface provides speech-to-text transcription, text-to-speech synthesis, and audio recording capabilities for the RAG Multimodal Banking Assistant.

**Implementation Status:** ‚úÖ Complete  
**Lines of Code:** ~1,550  
**Components:** 7

---

## üöÄ Quick Start

### 1. Basic Usage in Chat

The voice button is already integrated into the chat input:

```tsx
// Chat page automatically includes voice controls
import { ChatInput } from '@/components/chat/ChatInput';

<ChatInput onSendMessage={handleSend} />
```

**User Flow:**
1. Click the microphone icon üé§ in chat input
2. Grant microphone permission (first time only)
3. Click "Start Recording"
4. Speak your message
5. Click "Stop Recording"
6. Click "Transcribe"
7. Transcribed text auto-fills the input
8. Send message as normal

### 2. Standalone Voice Controls

Use the `VoiceControls` component anywhere:

```tsx
import { VoiceControls } from '@/components/voice';

export function MyComponent() {
  const handleTranscription = (text: string) => {
    console.log('User said:', text);
    // Do something with the transcribed text
  };

  return (
    <VoiceControls
      onTranscription={handleTranscription}
      onError={(error) => console.error(error)}
    />
  );
}
```

### 3. Custom Voice Hook

For complete control, use the `useVoice` hook:

```tsx
import { useVoice } from '@/components/voice';

export function CustomRecorder() {
  const voice = useVoice({
    autoTranscribe: true,
    language: 'en-US',
    onTranscription: (text) => {
      console.log('Transcribed:', text);
    },
  });

  return (
    <div>
      <button onClick={voice.startRecording}>
        {voice.isRecording ? '‚èπÔ∏è Stop' : 'üé§ Record'}
      </button>
      
      {voice.transcription.text && (
        <p>{voice.transcription.text}</p>
      )}
      
      <button onClick={() => voice.speak('Hello world')}>
        üîä Speak
      </button>
    </div>
  );
}
```

---

## üìã Common Use Cases

### Recording & Transcription

```tsx
const voice = useVoice({
  autoTranscribe: true,
  language: 'en-US',
});

// Start recording
await voice.startRecording();

// Stop recording (auto-transcribe if enabled)
voice.stopRecording();

// Manual transcription
await voice.transcribeRecording();

// Access result
const text = voice.transcription.text;
const confidence = voice.transcription.confidence;
```

### Text-to-Speech

```tsx
const voice = useVoice();

// Basic TTS
await voice.speak('Hello, welcome to our banking service!');

// With options
await voice.speak('Hello!', {
  speed: 1.5,        // 0.5x to 2.0x
  language: 'en-US',
  voice: 'female',   // if supported
});

// Stop speaking
voice.stopSpeaking();
```

### Multi-Language Support

```tsx
const voice = useVoice({
  language: 'es-ES', // Spanish
});

// Change language dynamically
voice.updateSettings({ language: 'fr-FR' }); // French

// Supported languages:
// en-US, en-GB, es-ES, fr-FR, de-DE, it-IT,
// pt-PT, zh-CN, ja-JP, ko-KR
```

### Permission Handling

```tsx
const voice = useVoice();

// Check permission status
if (!voice.hasPermission) {
  const granted = await voice.requestPermission();
  
  if (!granted) {
    alert('Microphone access required');
  }
}

// Start recording only if permitted
if (voice.hasPermission) {
  await voice.startRecording();
}
```

---

## üé® Component Examples

### VoiceRecorder Component

```tsx
import { VoiceRecorder } from '@/components/voice';

<VoiceRecorder
  isRecording={voice.isRecording}
  isPaused={voice.isPaused}
  duration={voice.recordingDuration}
  waveformData={voice.waveformData}
  onStart={voice.startRecording}
  onStop={voice.stopRecording}
  onPause={voice.pauseRecording}
  onResume={voice.resumeRecording}
  onCancel={voice.cancelRecording}
  onSend={() => voice.transcribeRecording()}
/>
```

**Features:**
- 40-bar animated waveform
- Duration timer (MM:SS format)
- Pause/resume controls
- Visual recording indicator

### AudioPlayer Component

```tsx
import { AudioPlayer } from '@/components/voice';

<AudioPlayer
  audio={voice.currentAudio}
  isPlaying={voice.isSpeaking}
  onPlay={() => voice.currentAudio?.play()}
  onPause={() => voice.currentAudio?.pause()}
  onStop={voice.stopSpeaking}
/>
```

**Features:**
- Progress bar with seek
- Play/pause/restart controls
- Volume slider with mute
- Time display

### VoiceControls Component

```tsx
import { VoiceControls } from '@/components/voice';

// Full interface
<VoiceControls
  onTranscription={(text) => handleText(text)}
  onError={(error) => handleError(error)}
/>

// Compact mode (icon only)
<VoiceControls
  compact={true}
  onTranscription={handleText}
/>
```

**Features:**
- Complete recording interface
- Settings panel
- Permission request UI
- TTS test input
- Error handling

---

## ‚öôÔ∏è Configuration

### Voice Settings

```tsx
const voice = useVoice();

// Update settings
voice.updateSettings({
  language: 'en-US',      // Transcription language
  autoTranscribe: true,   // Auto-transcribe after recording
  ttsEnabled: true,       // Enable text-to-speech
  ttsSpeed: 1.2,         // Speech speed (0.5 - 2.0)
  ttsVoice: 'female',    // Voice selection (if available)
});

// Access current settings
console.log(voice.settings);
```

### API Configuration

The voice API client is pre-configured:

```tsx
import { voiceApi } from '@/lib/api/voice';

// Transcribe audio file
const result = await voiceApi.transcribeAudio(audioFile, 'en-US');

// Transcribe base64
const result = await voiceApi.transcribeBase64(
  base64Audio,
  'en-US',
  'wav'
);

// Generate speech
const audio = await voiceApi.synthesizeAudioFile('Hello!', {
  language: 'en-US',
  speed: 1.0,
  format: 'mp3',
});
```

---

## üîß Advanced Usage

### Custom Waveform Visualization

```tsx
const voice = useVoice();

// Access waveform data
const { data, maxAmplitude } = voice.waveformData;

// data: number[] - Array of amplitude values (-1 to 1)
// maxAmplitude: number - Peak amplitude in current frame

// Render custom visualization
<canvas ref={canvasRef} />
<script>
  useEffect(() => {
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    
    // Draw waveform
    data.forEach((value, index) => {
      const height = Math.abs(value) * 100;
      ctx.fillRect(index * 5, 50 - height/2, 3, height);
    });
  }, [data]);
</script>
```

### Recording with Pause/Resume

```tsx
const voice = useVoice();

// Start recording
await voice.startRecording();

// Pause (waveform freezes)
voice.pauseRecording();

// Resume (waveform resumes)
voice.resumeRecording();

// Stop (generates final recording)
voice.stopRecording();

// Cancel (discards recording)
voice.cancelRecording();
```

### Error Handling

```tsx
const voice = useVoice({
  onError: (error) => {
    if (error.message.includes('permission')) {
      alert('Please grant microphone access');
    } else if (error.message.includes('network')) {
      alert('Network error. Please try again.');
    } else {
      console.error('Voice error:', error);
    }
  },
});
```

### State Management

```tsx
const voice = useVoice();

// Recording state
voice.isRecording    // boolean
voice.isPaused       // boolean
voice.recordingDuration // number (seconds)
voice.recording      // AudioRecording | null
voice.waveformData   // WaveformData

// Transcription state
voice.transcription.text         // string
voice.transcription.isTranscribing // boolean
voice.transcription.confidence   // number (0-1)
voice.transcription.duration     // number (seconds)
voice.transcription.error        // string | undefined

// TTS state
voice.isSpeaking     // boolean
voice.currentAudio   // HTMLAudioElement | null

// Permission state
voice.hasPermission  // boolean
```

---

## üß™ Testing

### Manual Testing Checklist

```bash
# 1. Permission
‚ñ° Click voice button
‚ñ° Grant microphone permission
‚ñ° Verify permission granted

# 2. Recording
‚ñ° Start recording
‚ñ° Verify waveform animating
‚ñ° Verify duration timer running
‚ñ° Speak clearly
‚ñ° Stop recording
‚ñ° Verify recording saved

# 3. Transcription
‚ñ° Click "Transcribe"
‚ñ° Verify loading indicator
‚ñ° Verify transcribed text displayed
‚ñ° Verify confidence score shown
‚ñ° Check text accuracy

# 4. TTS
‚ñ° Enter text in TTS input
‚ñ° Click speak button
‚ñ° Verify audio plays
‚ñ° Test pause/resume
‚ñ° Test volume control
‚ñ° Test speed adjustment

# 5. Chat Integration
‚ñ° Click mic in chat input
‚ñ° Record voice message
‚ñ° Transcribe
‚ñ° Verify text auto-fills chat input
‚ñ° Send message
```

### Browser Testing

**Supported Browsers:**
- ‚úÖ Chrome 47+
- ‚úÖ Firefox 25+
- ‚úÖ Edge 79+
- ‚úÖ Safari 14.1+
- ‚ùå Internet Explorer (not supported)

**Testing Checklist:**
```bash
# Chrome
‚ñ° Voice recording works
‚ñ° Waveform visualization smooth
‚ñ° TTS playback works

# Firefox
‚ñ° Voice recording works
‚ñ° Permission dialog appears
‚ñ° Audio playback works

# Safari
‚ñ° Request permission explicitly
‚ñ° Test audio recording
‚ñ° Test playback controls

# Edge
‚ñ° Full functionality test
‚ñ° Check waveform performance
```

---

## üêõ Troubleshooting

### Microphone Not Working

```typescript
// Check permission status
const permission = await navigator.permissions.query({ 
  name: 'microphone' 
});

if (permission.state === 'denied') {
  alert('Microphone access denied. Please enable in browser settings.');
}

// Check if getUserMedia is supported
if (!navigator.mediaDevices?.getUserMedia) {
  alert('Voice recording not supported in this browser');
}
```

### No Audio Output

```typescript
// Check if browser supports audio
const audio = new Audio();
const canPlayMP3 = audio.canPlayType('audio/mp3');
const canPlayWAV = audio.canPlayType('audio/wav');

if (!canPlayMP3 && !canPlayWAV) {
  alert('Audio playback not supported');
}

// Check volume
if (voice.currentAudio) {
  console.log('Volume:', voice.currentAudio.volume);
  console.log('Muted:', voice.currentAudio.muted);
}
```

### Transcription Fails

```typescript
// Check recording
if (!voice.recording?.blob) {
  console.error('No recording available');
}

// Check file size
if (voice.recording?.blob.size === 0) {
  console.error('Recording is empty');
}

// Check network
try {
  await voiceApi.transcribeAudio(audioBlob);
} catch (error) {
  if (error.response?.status === 401) {
    console.error('Authentication required');
  } else if (error.response?.status === 413) {
    console.error('File too large');
  } else {
    console.error('Network error:', error);
  }
}
```

### HTTPS Required

```bash
# Voice features require HTTPS in production
# For local development:

# Option 1: Use localhost (automatically secure)
npm run dev
# Access at http://localhost:3000

# Option 2: Use ngrok for HTTPS
ngrok http 3000
# Access at https://xxxx.ngrok.io

# Option 3: Generate local SSL certificate
mkcert localhost
npm run dev -- --https
```

---

## üìä Performance Tips

### Optimize Recording

```tsx
// Use smaller FFT size for better performance
const audioContext = new AudioContext();
const analyser = audioContext.createAnalyser();
analyser.fftSize = 128; // Smaller = better performance

// Sample waveform data
const sampleRate = 20; // Hz (lower = better performance)
```

### Lazy Load Voice Components

```tsx
import dynamic from 'next/dynamic';

// Lazy load voice controls (saves initial bundle size)
const VoiceControls = dynamic(
  () => import('@/components/voice').then(mod => mod.VoiceControls),
  { ssr: false }
);
```

### Cache TTS Audio

```tsx
const audioCache = new Map<string, Blob>();

const speakWithCache = async (text: string) => {
  // Check cache
  if (audioCache.has(text)) {
    const cachedAudio = audioCache.get(text)!;
    const url = URL.createObjectURL(cachedAudio);
    const audio = new Audio(url);
    await audio.play();
    return;
  }
  
  // Generate and cache
  const audioBlob = await voiceApi.synthesizeAudioFile(text);
  audioCache.set(text, audioBlob);
  
  const url = URL.createObjectURL(audioBlob);
  const audio = new Audio(url);
  await audio.play();
};
```

---

## üîê Security Notes

### HTTPS Requirement

```bash
# Production MUST use HTTPS
# Microphone access is blocked on non-HTTPS origins
# (except localhost for development)

# ‚úÖ Allowed
https://yourapp.com
http://localhost:3000
http://127.0.0.1:3000

# ‚ùå Blocked
http://yourapp.com
http://192.168.1.100:3000
```

### Permission Best Practices

```tsx
// 1. Request permission only when needed
// DON'T request on page load
// DO request when user clicks voice button

// 2. Handle permission denial gracefully
const voice = useVoice({
  onError: (error) => {
    if (error.message.includes('permission')) {
      showPermissionDialog();
    }
  },
});

// 3. Show clear permission UI
{!voice.hasPermission && (
  <Alert>
    Microphone access required for voice input.
    <Button onClick={voice.requestPermission}>
      Grant Permission
    </Button>
  </Alert>
)}
```

### Data Privacy

```tsx
// Voice recordings are NOT stored by default
// Transcriptions are sent to backend for processing
// TTS text is sent to speech synthesis API

// To implement recording storage:
const saveRecording = async (recording: AudioRecording) => {
  const formData = new FormData();
  formData.append('audio', recording.blob);
  
  await apiClient.post('/api/recordings', formData);
};
```

---

## üìö API Reference

### useVoice Hook

```typescript
interface UseVoiceOptions {
  onTranscription?: (text: string) => void;
  onError?: (error: Error) => void;
  autoTranscribe?: boolean;
  language?: string;
}

const voice = useVoice(options);

// Recording Methods
voice.startRecording(): Promise<void>
voice.stopRecording(): void
voice.pauseRecording(): void
voice.resumeRecording(): void
voice.cancelRecording(): void

// Transcription Methods
voice.transcribeRecording(recording?: AudioRecording): Promise<void>

// TTS Methods
voice.speak(text: string, options?: SpeakOptions): Promise<void>
voice.stopSpeaking(): void

// Settings Methods
voice.updateSettings(updates: Partial<VoiceSettings>): void

// Permission Methods
voice.requestPermission(): Promise<boolean>
```

### Voice API Client

```typescript
// Transcription
voiceApi.transcribeAudio(
  audioFile: File | Blob,
  language?: string
): Promise<TranscriptionResult>

voiceApi.transcribeBase64(
  audioBase64: string,
  language?: string,
  format?: string
): Promise<TranscriptionResult>

// Text-to-Speech
voiceApi.synthesizeSpeech(
  text: string,
  options?: SynthesisOptions
): Promise<SynthesisResult>

voiceApi.synthesizeAudioFile(
  text: string,
  options?: SynthesisOptions
): Promise<Blob>
```

---

## üéØ Next Steps

1. **Try the Chat Integration**
   - Open chat page
   - Click microphone icon
   - Record and transcribe

2. **Test TTS**
   - Open voice controls
   - Enter text in TTS input
   - Click speak button

3. **Explore Settings**
   - Change language
   - Adjust speech speed
   - Toggle auto-transcribe

4. **Customize**
   - Use `useVoice` hook in your components
   - Build custom voice interfaces
   - Integrate with your workflows

---

## üí° Tips & Tricks

### Quick Voice Message in Chat

```bash
1. Click mic icon üé§
2. Click "Start Recording"
3. Speak your message
4. Click "Stop"
5. Click "Transcribe"
6. Text auto-fills ‚Üí Click "Send"
```

### Keyboard Shortcuts (TODO)

```tsx
// Future enhancement: keyboard shortcuts
// Space: Toggle recording
// Enter: Send transcription
// Escape: Cancel recording
```

### Best Recording Practices

- üé§ Speak clearly and at a normal pace
- üîá Minimize background noise
- üìè Keep recordings under 1 minute for best results
- üåê Use correct language setting
- ‚úÖ Test microphone before important recordings

---

## üìû Support

**Issues?**
- Check browser console for errors
- Verify HTTPS/localhost
- Check microphone permissions
- Test in different browser

**Documentation:**
- `VOICE_INTERFACE_COMPLETE.md` - Full technical documentation
- `PROJECT_STATUS.md` - Overall project status
- Backend API docs at `/docs` (when running)

---

**Version:** 1.0  
**Last Updated:** 2025-01-17  
**Status:** ‚úÖ Production Ready